---
menu:
  default:
    identifier: secure-storage-connector
    parent: data-security
title: Bring your own bucket (BYOB)
weight: 1
---

## Overview
Bring your own bucket (BYOB) allows you to store W&B artifacts and other related sensitive data in your own cloud or on-prem infrastructure. In case of [Dedicated cloud]({{< relref "/guides/hosting/hosting-options/dedicated_cloud.md" >}}) or [Multi-tenant Cloud]({{< relref "/guides/hosting/hosting-options/saas_cloud.md" >}}), data that you store in your bucket is not copied to the W&B managed infrastructure.

{{% alert %}}
* Communication between W&B SDK / CLI / UI and your buckets occurs using [pre-signed URLs]({{< relref "./presigned-urls.md" >}}).
* W&B uses a garbage collection process to delete W&B Artifacts. For more information, see [Deleting Artifacts]({{< relref "/guides/core/artifacts/manage-data/delete-artifacts.md" >}}).
* You can specify a sub-path when configuring a bucket, to ensure that W&B does not store any files in a folder at the root of the bucket. It can help you better conform to your organzation's bucket governance policy.
{{% /alert %}}

### Data stored in the central database vs buckets
When using BYOB functionality, certain types of data will be stored in the W&B central database, and other types will be stored in your bucket. 

#### Database
- Metadata for users, teams, artifacts, experiments, and projects
- Reports
- Experiment logs
- System metrics
- Console logs

#### Buckets
- Experiment files and metrics
- Artifact files
- Media files
- Run files
- Exported history metrics and system events in Parquet format

### Bucket scopes
There are two scopes you can configure your storage bucket to:

| Scope          | Description |
|----------------|-------------|
| Instance level | In [Dedicated Cloud]({{< relref "/guides/hosting/hosting-options/dedicated_cloud/" >}}) and [Self-managed]({{< relref "/guides/hosting/hosting-options/self-managed.md" >}}), any user with the required permissions within your organization or instance can access files stored in your instance's storage bucket. Not applicable to [Multi-tenant Cloud]({{< relref "/guides/hosting/hosting-options/saas_cloud.md" >}}). |
| Team level     | If a W&B Team is configured to use a Team level storage bucket, team members can access files stored in it. Team level storage buckets allow greater data access control and data isolation for teams with highly sensitive data or strict compliance requirements.<br><br>Team level storage can help different business units or departments sharing an instance to efficiently use the infrastructure and administrative resources. It can also allow separate project teams to manage AI workflows for separate customer engagements. Available for all deployment types. You configure team level BYOB when setting up the team. |

This flexible design allows for many different storage topologies, depending on your organization's needs. For example:
- The same bucket can be used for the instance and one or more teams.
- Each team can use a separate bucket, some teams can choose to write to the instance bucket, or multiple teams can share a bucket by writing to subpaths.
- Buckets for different teams can be hosted in different cloud infrastructure environments or regions, and can be managed by different storage admin teams.

For example, suppose you have a team called Kappa in your organization. Your organization (and Team Kappa) use the Instance level storage bucket by default. Next, you create a team called Omega. When you create Team Omega, you configure a Team level storage bucket for that team. Files generated by Team Omega are not accessible by Team Kappa. However, files created by Team Kappa are accessible by Team Omega. If you want to isolate data for Team Kappa, you must configure a Team level storage bucket for them as well.

### Availability matrix
W&B can connect to the following types of storage:
- [CoreWeave AI Object Storage](https://docs.coreweave.com/docs/products/storage/object-storage) is a high-performance, S3-compatible object storage service optimized for AI workloads.
- [Amazon S3](https://aws.amazon.com/s3/) is an object storage service offering industry-leading scalability, data availability, security, and performance.
- [Google Cloud Storage](https://cloud.google.com/storage) is a managed service for storing unstructured data at scale.
- [Azure Blob Storage](https://azure.microsoft.com/products/storage/blobs) is a cloud-based object storage solution for storing massive amounts of unstructured data like text, binary data, images, videos, and logs.
- S3-compatible storage like [MinIO](https://github.com/minio/minio) hosted in your cloud or infrastructure on your premises.

The following table shows the availability of BYOB across different W&B Server deployment types. An `X` means the feature is available on the specific deployment type.

| W&B Server deployment type | Instance level                         | Team level | Additional information |
|----------------------------|----------------------------------------|------------|------------------------|
| Dedicated Cloud            | X<sup><a href="footnote_1">1</a></sup> | X          | Instance and team level BYOB are supported for AWS S3, GCP Storage, Microsoft Azure Blob Storage, and S3-compatible storage like [MinIO](https://github.com/minio/minio) hosted in your cloud or on-prem infrastructure.<br><br>CoreWeave AI Object Storage is available for team level BYOB. |
| SaaS Cloud                 | Not Applicable                         | X          | Team level BYOB is supported for CoreWeave AI Object Storage, AWS S3, and GCP Storage. W&B fully manages the default and only storage bucket for Microsoft Azure. |
| Self-Managed               | X<sup><a href="footnote_1">1</a></sup> | X          | Instance and team level BYOB are supported for AWS S3, GCP Storage, Microsoft Azure Blob Storage, and S3-compatible storage like [MinIO](https://github.com/minio/minio) hosted in your cloud or infrastructure on your premises.<br><br>CoreWeave AI Object Storage is available for team level BYOB. |

<sup><a id="footnote_1">1</a>.</sup> CoreWeave AI Object Storage is currently supported only for team level BYOB. Instance level support for Dedicated Cloud and Self-Hosted is coming soon.

## Set up BYOB
### 1. Provision your bucket {#provision-your-bucket}

After [verifying availability]({{< relref "#availability-matrix" >}}), you are ready to provision your storage bucket, including its access policy and CORS. Select a tab to continue.

{{< tabpane text=true >}}
{{% tab header="CoreWeave" value="coreweave" %}}
**Requirements**
- A CoreWeave account is required with AI Object Storage enabled and with permission to create buckets, API access keys, and secret keys.
- Ensure that your W&B instance can reach CoreWeave network endpoints.

For details, see [Create a CoreWeave AI Object Storage bucket](https://docs.coreweave.com/docs/products/storage/object-storage/how-to/create-bucket) in the CoreWeave documentation.

1. Create the bucket with a name of your choice in your preferred CoreWeave availability zone. Optionally create a folder for W&B to use as a sub-path for all W&B files. Make a note of the bucket name, availability zone, API access key, secret key, and sub-path.
1. Set the following Cross-origin resource sharing (CORS) policy for the bucket:
    ```json
    [
      {
        "AllowedHeaders": [
          "*"
        ],
        "AllowedMethods": [
          "GET",
          "HEAD",
          "PUT"
        ],
        "AllowedOrigins": [
          "*"
        ],
        "ExposeHeaders": [
          "ETag"
        ],
        "MaxAgeSeconds": 3000
      }
    ]
    ```
1. Generate API access tokens with appropriate permissions for these bucket operations: `GetObject`, `PutObject`, `DeleteObject`, `ListBucket`. See [Create an API access token](https://docs.coreweave.com/docs/products/storage/object-storage/how-to/create-access-tokens) in the CoreWeave documentation.
1. Configure bucket permissions to allow W&B to generate pre-signed URLs for secure access. (TODO HOW) 

Keep a record of the bucket name and access credentials. If you are using Dedicated cloud, share the bucket details with your W&B team in case of instance level BYOB. In case of team level BYOB on any deployment type, configure the bucket while creating the team.
{{% /tab %}}
{{% tab header="AWS" value="aws" %}}
For details, see [Create an S3 bucket](https://docs.aws.amazon.com/AmazonS3/latest/userguide/create-bucket-overview.html) in the AWS documentation.
1. Provision the KMS Key.

    W&B requires you to provision a KMS Key to encrypt and decrypt the data on the S3 bucket. The key usage type must be `ENCRYPT_DECRYPT`. Assign the following policy to the key:

    ```json
    {
      "Version": "2012-10-17",
      "Statement": [
        {
          "Sid" : "Internal",
          "Effect" : "Allow",
          "Principal" : { "AWS" : "<Your_Account_Id>" },
          "Action" : "kms:*",
          "Resource" : "<aws_kms_key.key.arn>"
        },
        {
          "Sid" : "External",
          "Effect" : "Allow",
          "Principal" : { "AWS" : "<aws_principal_and_role_arn>" },
          "Action" : [
            "kms:Decrypt",
            "kms:Describe*",
            "kms:Encrypt",
            "kms:ReEncrypt*",
            "kms:GenerateDataKey*"
          ],
          "Resource" : "<aws_kms_key.key.arn>"
        }
      ]
    }
    ```

    Replace `<Your_Account_Id>` and `<aws_kms_key.key.arn>` accordingly.

    If you are using [SaaS Cloud]({{< relref "/guides/hosting/hosting-options/saas_cloud.md" >}}) or [Dedicated cloud]({{< relref "/guides/hosting/hosting-options/dedicated_cloud.md" >}}), replace `<aws_principal_and_role_arn>` with the corresponding value:

    * For [SaaS Cloud]({{< relref "/guides/hosting/hosting-options/saas_cloud.md" >}}): `arn:aws:iam::725579432336:role/WandbIntegration`
    * For [Dedicated cloud]({{< relref "/guides/hosting/hosting-options/dedicated_cloud.md" >}}): `arn:aws:iam::830241207209:root`

    This policy grants your AWS account full access to the key and also assigns the required permissions to the AWS account hosting the W&B Platform. Keep a record of the KMS Key ARN.

1. Provision the S3 Bucket.

    Follow these steps to provision the S3 bucket in your AWS account:

    1. Create the S3 bucket with a name of your choice. Optionally create a folder which you can configure as sub-path to store all W&B files.
    1. Enable server side encryption, using the KMS key from the previous step.
    1. Configure CORS with the following policy:

        ```json
        [
          {
              "AllowedHeaders": [
                  "*"
              ],
              "AllowedMethods": [
                  "GET",
                  "HEAD",
                  "PUT"
              ],
              "AllowedOrigins": [
                  "*"
              ],
              "ExposeHeaders": [
                  "ETag"
              ],
              "MaxAgeSeconds": 3000
          }
        ]
        ```
        {{% alert %}}If data in your bucket expires due to an [object lifecycle management policy](https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lifecycle-mgmt.html), you may lose the ability to read the history of some runs.{{% /alert %}}
    1. Grant the required S3 permissions to the AWS account hosting the W&B Platform, which requires these permissions to generate [pre-signed URLs]({{< relref "./presigned-urls.md" >}}) that AI workloads in your cloud infrastructure or user browsers utilize to access the bucket.

        ```json
        {
          "Version": "2012-10-17",
          "Id": "WandBAccess",
          "Statement": [
            {
              "Sid": "WAndBAccountAccess",
              "Effect": "Allow",
              "Principal": { "AWS": "<aws_principal_and_role_arn>" },
                "Action" : [
                  "s3:GetObject*",
                  "s3:GetEncryptionConfiguration",
                  "s3:ListBucket",
                  "s3:ListBucketMultipartUploads",
                  "s3:ListBucketVersions",
                  "s3:AbortMultipartUpload",
                  "s3:DeleteObject",
                  "s3:PutObject",
                  "s3:GetBucketCORS",
                  "s3:GetBucketLocation",
                  "s3:GetBucketVersioning"
                ],
              "Resource": [
                "arn:aws:s3:::<wandb_bucket>",
                "arn:aws:s3:::<wandb_bucket>/*"
              ]
            }
          ]
        }
        ```

        Replace `<wandb_bucket>` accordingly and keep a record of the bucket name. If you are using [Dedicated cloud]({{< relref "/guides/hosting/hosting-options/dedicated_cloud.md" >}}), share the bucket name with your W&B team in case of instance level BYOB. In case of team level BYOB on any deployment type, [configure the bucket while creating the team]({{< relref "#configure-byob-in-wb" >}}).

        If you are using [SaaS Cloud]({{< relref "/guides/hosting/hosting-options/saas_cloud.md" >}}) or [Dedicated cloud]({{< relref "/guides/hosting/hosting-options/dedicated_cloud.md" >}}), replace `<aws_principal_and_role_arn>` with the corresponding value.

        * For [SaaS Cloud]({{< relref "/guides/hosting/hosting-options/saas_cloud.md" >}}): `arn:aws:iam::725579432336:role/WandbIntegration`
        * For [Dedicated cloud]({{< relref "/guides/hosting/hosting-options/dedicated_cloud.md" >}}): `arn:aws:iam::830241207209:root`
  
For more details, see the [AWS self-managed hosting guide]({{< relref "/guides/hosting/hosting-options/self-managed/install-on-public-cloud/aws-tf.md" >}}).
{{% /tab %}}
{{% tab header="GCP" value="gcp"%}}
For details, see [Create a bucket](https://cloud.google.com/storage/docs/creating-buckets) in the GCP documentation.
1. Provision the GCS bucket.

    Follow these steps to provision the GCS bucket in your GCP project:

    1. Create the GCS bucket with a name of your choice. Optionally create a folder which you can configure as sub-path to store all W&B files.
    1. Set encryption type to `Google-managed`.
    1. Set the CORS policy with `gsutil`. This is not possible in the UI.

       1. Create a file called `cors-policy.json` locally.
       1. Copy the following CORS policy into the file and save it.

           ```json
           [
             {
               "origin": ["*"],
               "responseHeader": ["Content-Type"],
               "exposeHeaders": ["ETag"],
               "method": ["GET", "HEAD", "PUT"],
               "maxAgeSeconds": 3000
             }
           ]
           ```

          {{% alert %}}If data in your bucket expires due to an [object lifecycle management policy](https://cloud.google.com/storage/docs/lifecycle), you may lose the ability to read the history of some runs.{{% /alert %}}

      1. Replace `<bucket_name>` with the correct bucket name and run `gsutil`.

          ```bash
          gsutil cors set cors-policy.json gs://<bucket_name>
          ```

      1. Verify the bucket's policy. Replace `<bucket_name>` with the correct bucket name.
        
          ```bash
          gsutil cors get gs://<bucket_name>
          ```

1. If you are using [SaaS Cloud]({{< relref "/guides/hosting/hosting-options/saas_cloud.md" >}}) or [Dedicated cloud]({{< relref "/guides/hosting/hosting-options/dedicated_cloud.md" >}}), grant the `storage.admin` role to the GCP service account linked to the W&B Platform. W&B requires this role to check the bucket's CORS configuration and attributes, such as whether object versioning is enabled. If the service account does not have the `storage.admin` role, these checks result in a HTTP 403 error.

    * For [SaaS Cloud]({{< relref "/guides/hosting/hosting-options/saas_cloud.md" >}}), the account is: `wandb-integration@wandb-production.iam.gserviceaccount.com`
    * For [Dedicated cloud]({{< relref "/guides/hosting/hosting-options/dedicated_cloud.md" >}}) the account is: `deploy@wandb-production.iam.gserviceaccount.com`

    Keep a record of the bucket name. If you are using [Dedicated cloud]({{< relref "/guides/hosting/hosting-options/dedicated_cloud.md" >}}), share the bucket name with your W&B team in case of instance level BYOB. In case of team level BYOB on any deployment type, [configure the bucket while creating the team]({{< relref "#configure-byob-in-wb" >}}).
{{% /tab %}}

{{% tab header="Azure" value="azure" %}}
For details, see [Create a blob storage container](https://learn.microsoft.com/en-us/azure/storage/blobs/blob-containers-portal) in the Azure documentation.
1. Provision the Azure Blob Storage container.

    For the instance level BYOB, if you're not using [this Terraform module](https://github.com/wandb/terraform-azurerm-wandb/tree/main/examples/byob), follow the steps below to provision a Azure Blob Storage bucket in your Azure subscription:

    1. Create a bucket with a name of your choice. Optionally create a folder which you can configure as sub-path to store all W&B files.
    1. Configure the CORS policy on the bucket

        To set the CORS policy through the UI go to the blob storage, scroll down to `Settings/Resource Sharing (CORS)` and then set the following:

        | Parameter | Value |
        | --- | --- |
        | Allowed Origins | `*`  |
        | Allowed Methods | `GET`, `HEAD`, `PUT` |
        | Allowed Headers | `*` |
        | Exposed Headers | `*` |
        | Max Age | `3000` |

        {{% alert %}}If data in your bucket expires due to an [object lifecycle management policy](https://learn.microsoft.com/en-us/azure/storage/blobs/lifecycle-management-policy-configure?tabs=azure-portal), you may lose the ability to read the history of some runs.{{% /alert %}}
1. Generate a storage account access key and make a note of its name and the storage account name. If you are using [Dedicated cloud]({{< relref "/guides/hosting/hosting-options/dedicated_cloud.md" >}}), share the storage account name and access key with your W&B team using a secure sharing mechanism.

    For team level BYOB, W&B recommends that you use [Terraform](https://github.com/wandb/terraform-azurerm-wandb/tree/main/modules/secure_storage_connector) to provision the Azure Blob Storage bucket along with the necessary access mechanism and permissions. If you use [Dedicated cloud]({{< relref "/guides/hosting/hosting-options/dedicated_cloud.md" >}}), provide the OIDC issuer URL for your instance. Make a note of details that you need to [configure the bucket while creating the team]({{< relref "#configure-byob-in-wb" >}}):

    * Storage account name
    * Storage container name
    * Managed identity client id
    * Azure tenant id
{{% /tab %}}
{{% tab header="S3-compatible" value="s3-compatible" %}}
Create your S3-compatible bucket. Make a note of:
- Access key
- Secret access key
- URL endpoint
- Bucket name
- Folder path, if applicable.
- Region
{{% /tab %}}
{{< /tabpane >}}

### 2. Determine the storage address  {#determine-the-storage-address}
This section explains the syntax to use to connect W&B to a BYOB storage bucket. In the examples, replace placeholder values between angle brackets (`<>`) with your bucket's details.

Select a tab for detailed instructions.

{{< tabpane text=true >}}
{{% tab header="CoreWeave" value="coreweave" %}}
**Bucket format**:
```text
cw://<accessKey>:<secretAccessKey>@<coreweaveEndpoint>/<bucketName>?region=<region>&tls=true
```
- In the address, the `region` parameter is mandatory. CoreWeave uses availability zones. The `region` parameter is mandatory and must be set to the CoreWeave availability zone.
- Replace `<coreweaveEndpoint>` with one of:
  - `cwobject.com`: Primary HTTPS endpoint, TLS 1.3 required.
  - `cwlota.com`: LOTA HTTP (not HTTPS) endpoint. Omit the `tls=true` parameter.
  See the [CoreWeave documentation](https://docs.coreweave.com/docs/products/storage/object-storage/how-to/get-started-caios#3-create-a-bucket) for details.
- The `cw://` protocol specifier is preferred. However, CoreWeave buckets offer an optional S3-compatible mode when you use the `s3://` protocol specifier instead.
{{% /tab %}}
{{% tab header="AWS" value="aws" %}}
**Bucket format**:
```text
s3://<accessKey>:<secretAccessKey>@<s3_regional_url_endpoint>/<bucketName>?region=<region>
```
In the address, the `region` parameter is mandatory unless your W&B instance is deployed in AWS with `AWS_REGION` set to the bucket's AWS S3 region.
{{% /tab %}}
{{% tab header="GCP" value="gcp" %}}
**Bucket format**:
```text
gs://<serviceAccountEmail>:<urlEncodedPrivateKey>@<bucketName>
```
{{% /tab %}}
{{% tab header="Azure" value="azure" %}}
**Bucket format**:
```text
az://:<urlEncodedAccessKey>@<storageAccountName>/<containerName>
```
{{% /tab %}}
{{% tab header="S3-compatible" value="s3-compatible" %}}
**Bucket format**:
```text
s3://<accessKey>:<secretAccessKey>@<url_endpoint>/<bucketName>?region=<region>&tls=true
```
In the address, the `region` parameter is mandatory.

{{% alert %}}
This section is for S3-compatible storage buckets that are not hosted in S3, like [MinIO](https://github.com/minio/minio) hosted on your premises. For storage buckets hosted in AWS S3, see the **AWS** tab instead.

For Cloud-native storage buckets with an optional S3-compatible mode, use the Cloud-native protocol specifier when possible. For example, use `cw://` for a CoreWeave bucket, rather than `s3://`.
{{% /alert %}}
{{% /tab %}}
{{< /tabpane >}}

After determining the storage address, you are ready to [configure instance level BYOB]({{< relref "#configure-instance-level-byob" >}}) or [configure team level BYOB]({{< relref "#configure-team-level-byob" >}}).

### 3. Configure W&B  {#configure-byob}
After you [provision your bucket]({{< relref "#provision-your-bucket" >}}), and [determine its address](#determine-the-storage-address), you are ready to configure BYOB at the [instance level]({{< relref "#instance-level-byob" >}}) or [team level]({{< relref "#team-level-byob" >}}).

{{% alert color="secondary" %}}
Plan your storage bucket layout carefully. After you configure a storage bucket for W&B, migrating its data to another bucket is complex and requires the assistance of W&B. This applies to storage for Dedicated Cloud and Self-Managed, as well as team-level storage for SaaS Cloud. For questions, contact [support](mailto:support@wandb.com).
{{% /alert %}}

#### Instance level BYOB
You can configure instance level BYOB for Dedicated Cloud or Self-Hosted using the W&B App or the `GORILLA_SUPPORTED_FILE_STORES` environment variable. Select a tab to continue.

{{< tabpane text=true >}}
{{% tab header="W&B App" %}}
To configure instance level BYOB:
1. Log in to W&B as a user with the `admin` role.
1. Click the user icon at the top, then click **System Console**.
1. Go to **Settings** > **System Connections**.
1. In the **Bucket Storage** section, ensure the identity in the **Identity** field is granted access to the new bucket.
1. Select the **Provider**.
1. Enter the new **Bucket Name**.
1. Optionally, enter the **Path** to use in the new bucket.
1. Click **Save**

{{% /tab %}}
{{% tab header="Environment variable" %}}

To configure instance level BYOB, set the `GORILLA_SUPPORTED_FILE_STORES` environment variable to the bucket location, then restart W&B. 
{{% /tab %}}
{{< /tabpane >}}

{{% alert %}}
W&B recommends that you use a Terraform module managed by W&B to provision a storage bucket along with the necessary access mechanism and related IAM permissions:

* [AWS](https://github.com/wandb/terraform-aws-wandb/tree/main/modules/secure_storage_connector)
* [GCP](https://github.com/wandb/terraform-google-wandb/tree/main/modules/secure_storage_connector)
* Azure - [Instance level BYOB](https://github.com/wandb/terraform-azurerm-wandb/tree/main/examples/byob) or [Team level BYOB](https://github.com/wandb/terraform-azurerm-wandb/tree/main/modules/secure_storage_connector)
{{% /alert %}}

#### Team level BYOB
After you [determine the storage location](#determine-the-storage-location) for your bucket, you can use the W&B App to configure team level BYOB while creating the team.

{{% alert %}}
After a team is created, its storage cannot be updated.
{{% /alert %}}

1. Log in to W&B as a user with the `admin` role.
1. Click the icon at the top left to open the left navigation, then click **Create a team to collaborate**..
1. Provide a name fore the team.
1. Set **Storage Type** to **External storage**.
1. Click **Bucket location**. Select an existing bucket or click **Add bucket** at the bottom to create a new bucket.
    To add a new bucket:
    1. Click **Cloud provider** and select **CoreWeave**, **AWS**, **GCP**, or **Azure**.
    1. Provide a **Name** for the bucket.
        - For **CoreWeave**, provide only the bucket name.
        - For Azure on W&B Dedicated or Self-managed, provide Account name and Container name (TODO verify UI)
    1. Provide the bucket path you [determined earlier](#determine-the-storage-address).
    1. (Optional) Set **Path** to the bucket sub-path.
    1. (Optional on AWS) Set **KMS key ARN** to the ARN of your KMS encryption key.
    1. (Optional on Azure) Set **Tenant ID** and **Managed Identity Client ID** fields to the appropriate values.
1. Optionally on SaaS Cloud, invite members to the team. In **Invite team members**, specify a comma-separated list of email addresses.
1. Click **Create team**.

If W&B encounters errors accessing the bucket or detects invalid settings, an error or warning displays at the bottom of the page. Otherwise, the team is created.
